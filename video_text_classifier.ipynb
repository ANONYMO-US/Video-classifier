{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video text classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSxxRTP7+eP/0t8rkTW6JG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANONYMO-US/Video-classifier/blob/master/video_text_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIeOH4kWRFai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "outputId": "3c667c7d-0a89-4330-a3c9-a991a7b907a3"
      },
      "source": [
        "import os\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import pandas as pd\n",
        "from termcolor import colored\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from matplotlib import pyplot\n",
        "from numpy import array\n",
        "\n",
        "print(colored(\"Loading train and test data\", \"blue\"))\n",
        "df = pd.read_csv(r'dsf2.csv')\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=1) \n",
        "print(colored(\"Data loaded\", \"blue\"))\n",
        "\n",
        "print(colored(\"Tokenizing and padding data\", \"blue\"))\n",
        "tokenizer = Tokenizer(num_words = 2000, split = ' ')\n",
        "tokenizer.fit_on_texts(train_data['Content'].astype(str).values)\n",
        "train_tweets = tokenizer.texts_to_sequences(train_data['Content'].astype(str).values)\n",
        "max_len = max([len(i) for i in train_tweets])\n",
        "train_tweets = pad_sequences(train_tweets, maxlen = max_len)\n",
        "test_tweets = tokenizer.texts_to_sequences(test_data['Content'].astype(str).values)\n",
        "test_tweets = pad_sequences(test_tweets, maxlen = max_len)\n",
        "print(colored(\"Tokenizing and padding complete\", \"blue\"))\n",
        "print(colored(\"Printing tweets converted to numeric vectors\",\"blue\"))\n",
        "\n",
        "\n",
        "print(colored(\"Creating the LSTM model\", \"blue\"))\n",
        "model = Sequential()\n",
        "model.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(256, dropout = 0.3))\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'RMSprop', metrics = ['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "print(colored(\"Training the LSTM model\", \"green\"))\n",
        "history = model.fit(train_tweets, pd.get_dummies(train_data['Label']).values, epochs = 10, batch_size = 256,validation_split=0.2)\n",
        "print(colored(history, \"green\"))\n",
        "\n",
        "print(colored(\"Testing the LSTM model\", \"green\"))\n",
        "score, accuracy = model.evaluate(test_tweets, pd.get_dummies(test_data['Label']).values, batch_size = 256)\n",
        "print(\"Test accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mLoading train and test data\u001b[0m\n",
            "\u001b[34mData loaded\u001b[0m\n",
            "\u001b[34mTokenizing and padding data\u001b[0m\n",
            "\u001b[34mTokenizing and padding complete\u001b[0m\n",
            "\u001b[34mPrinting tweets converted to numeric vectors\u001b[0m\n",
            "\u001b[34mCreating the LSTM model\u001b[0m\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 696, 128)          256000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 696, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 651,268\n",
            "Trainable params: 651,268\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\u001b[32mTraining the LSTM model\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1142 samples, validate on 286 samples\n",
            "Epoch 1/10\n",
            "1142/1142 [==============================] - 65s 57ms/step - loss: 0.5292 - accuracy: 0.7526 - val_loss: 0.5054 - val_accuracy: 0.7500\n",
            "Epoch 2/10\n",
            "1142/1142 [==============================] - 59s 52ms/step - loss: 0.8513 - accuracy: 0.7018 - val_loss: 1.3186 - val_accuracy: 0.5734\n",
            "Epoch 3/10\n",
            "1142/1142 [==============================] - 59s 52ms/step - loss: 0.8385 - accuracy: 0.7095 - val_loss: 0.5850 - val_accuracy: 0.7500\n",
            "Epoch 4/10\n",
            "1142/1142 [==============================] - 59s 52ms/step - loss: 0.4982 - accuracy: 0.8001 - val_loss: 0.4403 - val_accuracy: 0.8330\n",
            "Epoch 5/10\n",
            "1142/1142 [==============================] - 59s 52ms/step - loss: 0.4114 - accuracy: 0.8393 - val_loss: 0.3992 - val_accuracy: 0.8339\n",
            "Epoch 6/10\n",
            "1142/1142 [==============================] - 59s 52ms/step - loss: 0.3807 - accuracy: 0.8549 - val_loss: 0.4952 - val_accuracy: 0.7815\n",
            "Epoch 7/10\n",
            "1142/1142 [==============================] - 59s 52ms/step - loss: 0.3788 - accuracy: 0.8494 - val_loss: 0.3448 - val_accuracy: 0.8523\n",
            "Epoch 8/10\n",
            "1142/1142 [==============================] - 59s 52ms/step - loss: 0.3130 - accuracy: 0.8805 - val_loss: 0.3071 - val_accuracy: 0.8951\n",
            "Epoch 9/10\n",
            "1142/1142 [==============================] - 59s 52ms/step - loss: 0.2590 - accuracy: 0.9148 - val_loss: 0.2962 - val_accuracy: 0.8654\n",
            "Epoch 10/10\n",
            "1142/1142 [==============================] - 59s 52ms/step - loss: 0.3202 - accuracy: 0.8689 - val_loss: 0.3086 - val_accuracy: 0.8881\n",
            "\u001b[32m<keras.callbacks.callbacks.History object at 0x7f032e10c710>\u001b[0m\n",
            "\u001b[32mTesting the LSTM model\u001b[0m\n",
            "358/358 [==============================] - 5s 14ms/step\n",
            "Test accuracy: 0.8833798766136169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1oYtMhOSI8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}